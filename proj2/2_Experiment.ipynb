{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a788780-66c4-45f0-bb89-6ebbdb6322c7",
   "metadata": {},
   "source": [
    "# Experiment Notebook\n",
    "\n",
    "This notebook will contain the steps to run the experiments for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "013183da-e400-42ae-b48c-eee3c9a7f7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 21:18:46.779217: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731964726.796679   79142 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731964726.802108   79142 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-18 21:18:46.823079: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import time\n",
    "import random \n",
    "\n",
    "from modeling import rf, svm, lstm, gaussian\n",
    "from feature_engineering import extract_features\n",
    "from dataset_handling import book_train_test_split, load_dataset\n",
    "\n",
    "LOGGER_NAME = \"proj2_logger\"\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.logger = logging.getLogger(LOGGER_NAME)\n",
    "\n",
    "    def create_features(self, df: pd.DataFrame):\n",
    "        raise NotImplementedError(\"Function was not implemented in subclass\")\n",
    "    def fit(self) -> None:\n",
    "        raise NotImplementedError(\"Function was not implemented in subclass\")\n",
    "    def predict(self) -> []:\n",
    "        raise NotImplementedError(\"Function was not implemented in subclass\")\n",
    "\n",
    "class TransformerModel(Model):\n",
    "    def create_features(self, df: pd.DataFrame):\n",
    "        # split df into pre-created train-test groups\n",
    "        self.train_df = df[df['is_train']]\n",
    "        self.test_df = df[~df['is_train']]\n",
    "\n",
    "    def fit(self):\n",
    "        # fit transformer\n",
    "        return None\n",
    "    \n",
    "    def predict(self):\n",
    "        \n",
    "        self.tfidf, self.embeddings = extract_features(df)\n",
    "        self.labels = df['author_id']\n",
    "\n",
    "    def fit(self):\n",
    "        '''\n",
    "        To avoid reusing code, this function does nothing, as\n",
    "        the per-model functions already train and then test\n",
    "        '''\n",
    "        return None\n",
    "    \n",
    "    def predict(self):\n",
    "        # run all models and return metrics\n",
    "        functions = [rf, gaussian, svm, lstm]\n",
    "        metrics_arr = []\n",
    "        for feature_type in ['glove', 'tfidf']:\n",
    "            self.logger.debug(f\"Processing {feature_type} features\")\n",
    "            features = self.tfidf if feature_type == \"tfidf\" else self.embeddings\n",
    "            for function in functions:\n",
    "                try:\n",
    "                    start_time = time.time()\n",
    "                    self.logger.debug(f\"Beginning testing of {function.__name__} with {feature_type} features\")\n",
    "                    metrics, classification_report, pr = function(features, self.labels)\n",
    "                    self.logger.debug(classification_report)\n",
    "                    self.logger.debug(f\"Finished testing of {function.__name__} with {feature_type} features (took {time.time() - start_time} seconds)\")\n",
    "                    metrics_arr.append([function.__name__, feature_type, *metrics]\n",
    "                except Exception as e:\n",
    "                    print(e)  \n",
    "            self.logger.debug(f\"Finished processing {feature_type} features\")\n",
    "        return metrics_arr\n",
    "\n",
    "def experiment(datafile_path='data/dataset.parquet'):\n",
    "    # load dataset\n",
    "    # run train-test-split on df (will produce label column)\n",
    "    df = book_train_test_split(load_dataset(datafile_path))\n",
    "    models = [TransformerModel(), ClassicalModels()]\n",
    "    metrics = []\n",
    "    for model in models:\n",
    "        model.create_features(df)\n",
    "        model.fit()\n",
    "        metrics += model.predict()\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics, columns=['model_name', 'data_type', 'time', 'accuracy'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b96a48a-e018-423e-b64c-a34f135b11ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = book_train_test_split(load_dataset())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fc59390-f8ab-4bff-a756-1481c4487842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = book_train_test_split(load_dataset(\"data/primary_authors_dataset.parquet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db0d8b46-d5e1-4eca-8783-5ca6c395349f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe embeddings already exist.\n",
      "Loaded 2196008 word vectors.\n",
      "Average Number of Words not in Embedding Vocab: 3.4205376400652323\n",
      "Embeddings saved to document_embeddings.npy\n",
      "Computing TF-IDF scores...\n",
      "Average Number of Words not in Embedding Vocab: 955.8599084644115\n",
      "Embeddings saved to document_embeddings_tfidf.npy\n",
      "Extracting TF-IDF features...\n"
     ]
    }
   ],
   "source": [
    "tfidf, vecs = extract_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "655c6680-cd70-4d39-a70f-c3245bfbc5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.to_csv(\"data/primary_authors_tfidf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d52ebbf-48c4-4368-8af1-4531148649cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe embeddings already exist.\n",
      "Loaded 2196008 word vectors.\n",
      "Average Number of Words not in Embedding Vocab: 5.076604691522193\n",
      "Embeddings saved to document_embeddings.npy\n",
      "Computing TF-IDF scores...\n"
     ]
    }
   ],
   "source": [
    "tfidf, vecs = extract_features(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e665a0b-5845-4b35-bc20-786ee0d1e300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 16:41:11.764863: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732552871.784043  241008 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732552871.790068  241008 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-25 16:41:11.812708: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from contextlib import redirect_stdout\n",
    "from proj_logging import logger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support ,precision_score, recall_score, f1_score, precision_recall_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Input\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from proj_logging import logger\n",
    "from dataset_handling import get_config_metadata, write_config_metadata\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from timeit import default_timer as timer\n",
    "from pyspark.ml.stat import Summarizer\n",
    "from pyspark.sql.functions import udf, split, monotonically_increasing_id, explode, col, mean, concat, lit\n",
    "from pyspark.sql.types import DoubleType, ArrayType, StringType, MapType, StructType, StructField\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataset_handling import book_train_test_split\n",
    "import torch\n",
    "from feature_engineering import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3abc82b5-488b-40a3-a704-6c9e612f1283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>is_train</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.28832898, 0.38870975, 0.13632962, 0.520275,...</td>\n",
       "      <td>False</td>\n",
       "      <td>10294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.4572123, 0.3324129, 0.24623187, 0.5438165, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>10294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.46877238, 0.30636883, 0.30725992, 0.4327013...</td>\n",
       "      <td>False</td>\n",
       "      <td>10294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.3527186, 0.34149382, 0.30431616, 0.47463518...</td>\n",
       "      <td>False</td>\n",
       "      <td>10294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.41601232, 0.5375397, 0.2180003, 0.43813646,...</td>\n",
       "      <td>False</td>\n",
       "      <td>10294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19004</th>\n",
       "      <td>[0.37158808, 0.43231353, 0.27672166, 0.5070651...</td>\n",
       "      <td>False</td>\n",
       "      <td>5036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19005</th>\n",
       "      <td>[0.27637783, 0.32261384, 0.27342793, 0.3701268...</td>\n",
       "      <td>False</td>\n",
       "      <td>5036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19006</th>\n",
       "      <td>[0.52867526, 0.2188764, 0.4117935, 0.47598585,...</td>\n",
       "      <td>False</td>\n",
       "      <td>5036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19007</th>\n",
       "      <td>[0.39144635, 0.38395822, 0.40404236, 0.5401964...</td>\n",
       "      <td>False</td>\n",
       "      <td>5036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19008</th>\n",
       "      <td>[0.30883226, 0.48927873, 0.21406014, 0.4184271...</td>\n",
       "      <td>True</td>\n",
       "      <td>5036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19009 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                features  is_train author_id\n",
       "0      [0.28832898, 0.38870975, 0.13632962, 0.520275,...     False     10294\n",
       "1      [0.4572123, 0.3324129, 0.24623187, 0.5438165, ...     False     10294\n",
       "2      [0.46877238, 0.30636883, 0.30725992, 0.4327013...     False     10294\n",
       "3      [0.3527186, 0.34149382, 0.30431616, 0.47463518...     False     10294\n",
       "4      [0.41601232, 0.5375397, 0.2180003, 0.43813646,...     False     10294\n",
       "...                                                  ...       ...       ...\n",
       "19004  [0.37158808, 0.43231353, 0.27672166, 0.5070651...     False      5036\n",
       "19005  [0.27637783, 0.32261384, 0.27342793, 0.3701268...     False      5036\n",
       "19006  [0.52867526, 0.2188764, 0.4117935, 0.47598585,...     False      5036\n",
       "19007  [0.39144635, 0.38395822, 0.40404236, 0.5401964...     False      5036\n",
       "19008  [0.30883226, 0.48927873, 0.21406014, 0.4184271...      True      5036\n",
       "\n",
       "[19009 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = pd.read_parquet(\"data/primary_authors/document_embeddings.parquet\")\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "761ae753-7ea6-4bc4-bc4e-171fd99f98e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.functions import array_to_vector\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "# dataset = spark.read.parquet('data/primary_authors/document_embeddings.parquet')\n",
    "dataset = spark.read.parquet('data/all/document_embeddings.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb455ebc-d874-4d80-a9b4-c81fa479ca7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(book_id=12, final_vector=DenseVector([0.0091, 0.0575, -0.1319, -0.0732, 0.1199, 0.0529, 0.0602, -0.0561, -0.047, 1.3077, -0.1412, 0.0283, 0.0318, -0.0996, 0.0212, -0.0221, -0.1098, 0.9808, -0.1067, -0.0158, 0.0431, -0.0005, -0.0805, 0.0001, 0.0622, -0.0265, -0.0877, -0.0697, 0.0538, 0.0808, -0.0748, 0.0217, 0.0193, 0.0942, 0.069, -0.0642, 0.0748, 0.0614, -0.1318, -0.0138, 0.0468, 0.0264, 0.0032, -0.0297, 0.0206, 0.02, 0.0238, 0.0321, 0.0185, 0.0126, -0.0216, 0.0734, 0.0485, 0.022, 0.0053, -0.0116, -0.0443, -0.0204, -0.0251, -0.0702, -0.0263, 0.038, -0.01, 0.0958, -0.0039, 0.0184, 0.0301, 0.0009, 0.0106, 0.0358, -0.0265, 0.098, 0.0177, -0.0239, 0.1004, 0.0262, -0.0588, 0.0549, -0.0511, 0.0094, 0.0264, 0.1201, -0.087, 0.1064, 0.0449, -0.0766, 0.367, -0.197, 0.0181, -0.0099, -0.1296, -0.0379, 0.0033, -0.0438, 0.0849, 0.096, 0.0608, -0.0338, 0.0109, -0.0044, 0.0206, -0.017, -0.0296, 0.0028, 0.0158, -0.8623, 0.1151, 0.0587, 0.0012, -0.0064, -0.0452, -0.1528, 0.0304, -0.0347, -0.022, 0.074, -0.0854, -0.0134, -0.0192, -0.0245, 0.0704, -0.0398, -0.0349, 0.0144, -0.1106, 0.0519, 0.004, -0.1, 0.0583, -0.025, -0.0428, 0.0733, -0.0949, 0.0419, 0.0996, 0.0132, -0.0036, -0.0624, -0.0584, -0.0971, -1.0349, -0.0109, 0.0408, 0.0628, 0.0459, -0.031, 0.0188, 0.0834, -0.0058, -0.0651, -0.0128, -0.0064, 0.1043, -0.0711, -0.0288, -0.0508, -0.0851, -0.0042, 0.061, -0.0285, 0.063, -0.0087, -0.0378, 0.0538, 0.0019, -0.1204, -0.0145, -0.0259, 0.0254, 0.0138, -0.0369, -0.0483, -0.0017, -0.0639, -0.0255, -0.0102, -0.0089, 0.0488, -0.0761, -0.0285, 0.0031, -0.0491, -0.0513, -0.0196, -0.147, 0.0636, -0.1403, 0.0092, 0.1303, -0.006, 0.0138, -0.0022, -0.1551, -0.0053, 0.1448, 0.0663, -0.0524, -0.189, 0.0354, -0.007, 0.0175, -0.0074, -0.0516, 0.0885, 0.1119, -0.0549, -0.0014, 0.007, -0.0225, 0.0286, -0.0044, 0.0989, -0.0031, -0.1098, -0.0354, 0.0494, -0.0584, 0.0295, -0.0867, 0.0132, 0.063, -0.0311, -0.0296, -0.0123, -0.1096, 0.0563, -0.074, 0.0437, 0.0002, -0.0121, -0.0961, -0.0421, 0.0253, 0.0602, -0.117, -0.0968, -0.053, 0.0684, -0.131, 0.1413, 0.0759, 0.0739, 0.0575, 0.1393, 0.0753, -0.1421, 0.0232, -0.115, -0.0905, -0.0403, 0.0902, -0.0508, 0.0356, -0.0151, 0.0239, 0.144, 0.0485, -0.0074, -0.0579, 0.0273, -0.0077, 0.0966, 0.0625, 0.0375, 0.0699, -0.0544, -0.0143, 0.0296, 0.1814, -0.0509, 0.0509, 0.0053, -0.0225, 0.059, -0.0045, 0.0245, -0.0679, 0.0684, -0.0659, 0.0943, 0.1192, 0.0774, 0.0053, -0.0518, -0.0642, -0.0866, 0.1417, -0.0334, 0.1277, -0.0088, -0.0225, -0.0528, -0.0788, -0.1533, 0.0636, 0.0057, 0.0233, -0.0215, -0.0101, 0.0646]), author_id=14112)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57810771-9490-4544-bc68-052933b54965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/primary_authors/'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/primary_authors/dataset.parquet'\n",
    "path[:path.rindex('/')+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4a42084-4172-4718-bdc7-4f5ce82e1136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(author_id='5036', label=0.0),\n",
       " Row(author_id='3258', label=1.0),\n",
       " Row(author_id='10294', label=2.0),\n",
       " Row(author_id='3304', label=3.0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.select(\"author_id\", \"label\").distinct().write.csv("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d10575c9-cb27-4542-b2b4-231e8ac7e1ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `prediction` cannot be resolved. Did you mean one of the following? [`features`, `is_train`, `author_id`].;\n'Project ['prediction, 'label]\n+- Relation [features#18,is_train#19,author_id#20] parquet\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t \u001b[38;5;241m=\u001b[39m MulticlassMetrics(\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrdd)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:3229\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   3186\u001b[0m \n\u001b[1;32m   3187\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3227\u001b[0m \u001b[38;5;124;03m    +-----+---+\u001b[39;00m\n\u001b[1;32m   3228\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3229\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `prediction` cannot be resolved. Did you mean one of the following? [`features`, `is_train`, `author_id`].;\n'Project ['prediction, 'label]\n+- Relation [features#18,is_train#19,author_id#20] parquet\n"
     ]
    }
   ],
   "source": [
    "t = MulticlassMetrics(dataset.select(\"prediction\", \"label\").rdd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b942987e-b52c-43b9-b641-dd6f415021ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7310.,  610.,    0.,  183.],\n",
       "       [1166., 2800.,    0.,    0.],\n",
       "       [2205.,  118.,    0.,   59.],\n",
       "       [ 567.,   39.,    0.,  156.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.confusionMatrix().toArray().tofile("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e056935-fe15-4f90-a44b-560fdeb4e735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.082752, 0.67204, -0.14987, -0.064983, 0.056491, 0.40228, 0.0027747, -0.3311, -0.30691, 2.0817, 0.031819, 0.013643, 0.30265, 0.0071297, -0.5819, -0.2774, -0.062254, 1.1451, -0.24232, 0.1235, -0.12243, 0.33152, -0.006162, -0.30541, -0.13057, -0.054601, 0.037083, -0.070552, 0.5893, -0.30385, 0.2898, -0.14653, -0.27052, 0.37161, 0.32031, -0.29125, 0.0052483, -0.13212, -0.052736, 0.087349, -0.26668, -0.16897, 0.015162, -0.0083746, -0.14871, 0.23413, -0.20719, -0.091386, 0.40075, -0.17223, 0.18145, 0.37586, -0.28682, 0.37289, -0.16185, 0.18008, 0.3032, -0.13216, 0.18352, 0.095759, 0.094916, 0.008289, 0.11761, 0.34046, 0.03677, -0.29077, 0.058303, -0.027814, 0.082941, 0.1862, -0.031494, 0.27985, -0.074412, -0.13762, -0.21866, 0.18138, 0.040855, -0.113, 0.24107, 0.3657, -0.27525, -0.05684, 0.34872, 0.011884, 0.14517, -0.71395, 0.48497, 0.14807, 0.62287, 0.20599, 0.58379, -0.13438, 0.40207, 0.18311, 0.28021, -0.42349, -0.25626, 0.17715, -0.54095, 0.16596, -0.036058, 0.08499, -0.64989, 0.075549, -0.28831, 0.40626, -0.2802, 0.094062, 0.32406, 0.28437, -0.26341, 0.11553, 0.071918, -0.47215, -0.18366, -0.34709, 0.29964, -0.66514, 0.002516, -0.42333, 0.27512, 0.36012, 0.16311, 0.23964, -0.05923, 0.3261, 0.20559, 0.038677, -0.045816, 0.089764, 0.43151, -0.15954, 0.08532, -0.26572, -0.15001, 0.084286, -0.16714, -0.43004, 0.060807, 0.13121, -0.24112, 0.66554, 0.4453, -0.18019, -0.13919, 0.56252, 0.21457, -0.46443, -0.012211, 0.029988, -0.051094, -0.20135, 0.80788, 0.47377, -0.057647, 0.46216, 0.16084, -0.20954, -0.05452, 0.15572, -0.13712, 0.12972, -0.011936, -0.003378, -0.13595, -0.080711, 0.20065, 0.054056, 0.046816, 0.059539, 0.046265, 0.17754, -0.31094, 0.28119, -0.24355, 0.085252, -0.21011, -0.19472, 0.0027297, -0.46341, 0.14789, -0.31517, -0.065939, 0.036106, 0.42903, -0.33759, 0.16432, 0.32568, -0.050392, -0.054297, 0.24074, 0.41923, 0.13012, -0.17167, -0.37808, -0.23089, -0.019477, -0.29291, -0.30824, 0.30297, -0.22659, 0.081574, -0.18516, -0.21408, 0.40616, -0.28974, 0.074174, -0.17795, 0.28595, -0.039626, -0.2339, -0.36054, -0.067503, -0.091065, 0.23438, -0.0041331, 0.003232, 0.0072134, 0.008697, 0.21614, 0.049904, 0.35582, 0.13748, 0.073361, 0.14166, 0.2412, -0.013322, 0.15613, 0.083381, 0.088146, -0.019357, 0.43795, 0.083961, 0.45309, -0.50489, -0.10865, -0.2527, -0.18251, 0.20441, 0.13319, 0.1294, 0.050594, -0.15612, -0.39543, 0.12538, 0.24881, -0.1927, -0.31847, -0.12719, 0.4341, 0.31177, -0.0040946, -0.2094, -0.079961, 0.1161, -0.050794, 0.015266, -0.2803, -0.12486, 0.23587, 0.2339, -0.14023, 0.028462, 0.56923, -0.1649, -0.036429, 0.010051, -0.17107, -0.042608, 0.044965, -0.4393, -0.26137, 0.30088, -0.060772, -0.45312, -0.19076, -0.20288, 0.27694, -0.060888, 0.11944, 0.62206, -0.19343, 0.47849, -0.30113, 0.059389, 0.074901, 0.061068, -0.4662, 0.40054, -0.19099, -0.14331, 0.018267, -0.18643, 0.20709, -0.35598, 0.05338, -0.050821, -0.1918, -0.37846, -0.06589]\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "# Lead the txt into mem\n",
    "with open(\"glove.840B.300d.txt\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.strip().split(' ')\n",
    "        word = values[0]\n",
    "        try:\n",
    "            embedding = [float(x) for x in values[1:]]\n",
    "            embeddings_index[word] = embedding\n",
    "            print(embedding)\n",
    "            break\n",
    "        except ValueError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c98b7e5-f211-4289-8e53-bc2406d5fdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=[-0.033117614686489105, 0.12483888119459152, -0.1549590528011322, -0.05444326251745224, 0.10045762360095978, -0.05532223358750343, -0.0026100422255694866, -0.08408316224813461, -0.03065658174455166, 2.3531155586242676, -0.11757563799619675, -0.0012547832448035479, 0.06489349901676178, -0.07668668776750565, -0.14405636489391327, -0.07120014727115631, -0.08332885056734085, 0.932112455368042, -0.16846469044685364, -0.04060450568795204, 0.02029799297451973, -0.07106799632310867, -0.06717848777770996, -0.00455648684874177, 0.0029725641943514347, 0.025969045236706734, -0.07220955193042755, -0.05050615593791008, 0.03428267315030098, -0.07148827612400055, -0.05324846878647804, 0.1629950851202011, -0.0616370253264904, 0.06018863990902901, 0.0775580033659935, -0.0882159098982811, -0.03288496285676956, 0.0039817257784307, -0.07003581523895264, -0.09210877865552902, -0.009599561803042889, 0.11958678811788559, -0.012092802673578262, -0.0970168188214302, 0.08391684293746948, 0.0025610795710235834, -0.10697278380393982, -0.040820859372615814, 0.01754629984498024, 0.029467983171343803, -0.0639696791768074, 0.06902561336755753, -0.05311295762658119, 0.02016288973391056, 0.09377744048833847, 0.010480932891368866, -0.02275271899998188, -0.06056026369333267, -0.02128669247031212, -0.07074809819459915, -0.0009982542833313346, -0.02995940111577511, -0.06633947789669037, 0.12387998402118683, 0.033253200352191925, -0.04056509584188461, -0.03861774131655693, 0.04701641947031021, 0.06704041361808777, 0.0616486556828022, 0.05022525042295456, 0.04858491197228432, 0.1713162511587143, -0.050370484590530396, 0.07761601358652115, -0.011932207271456718, 0.07519057393074036, -0.09055464714765549, -0.04938611015677452, 0.16826772689819336, -0.024284392595291138, 0.048620857298374176, -0.17441757023334503, -0.06427251547574997, 0.044218290597200394, -0.18639038503170013, -0.029675224795937538, -0.1767309159040451, 0.16986137628555298, 0.013417968526482582, -0.1244347020983696, -0.003843878861516714, -0.023192226886749268, 0.040279973298311234, 0.09668155759572983, 0.016692442819476128, 0.0022713958751410246, -0.05988452583551407, 0.0040757497772574425, -0.05388602614402771, 0.0011548990150913596, 0.009127420373260975, -0.05451923608779907, -0.03307902067899704, 0.08624482154846191, -0.9571686387062073, 0.051595140248537064, 0.028557587414979935, -0.013276370242238045, -0.017843084409832954, 0.026077475398778915, -0.09712652862071991, 0.0889841839671135, -0.07354483753442764, 0.057219453155994415, -0.01622706465423107, 0.0036540806759148836, 0.0437002032995224, -0.04523693770170212, 0.019135726615786552, 0.0511358268558979, -0.09104470908641815, -0.012911994010210037, -0.0001246633764822036, 0.04236485809087753, 0.040779419243335724, -0.04486502334475517, -0.15099719166755676, 0.008578073233366013, -0.012241754680871964, -0.002931973896920681, -0.00864738505333662, -0.10255102068185806, 0.01331371907144785, 0.09630066156387329, 0.03406396135687828, 0.017383268103003502, -0.008950348012149334, 0.013127757236361504, -0.03879281133413315, -1.3073159456253052, 0.06838927417993546, 0.10614411532878876, 0.017500076442956924, 0.057572297751903534, -0.09308645874261856, -0.019148530438542366, 0.004914383869618177, 0.03349785506725311, -0.08638906478881836, -0.029016027227044106, -0.017808305099606514, 0.07886834442615509, -0.0027399067766964436, -0.058389812707901, -0.008912735618650913, -0.10227398574352264, -0.048012685030698776, -0.05972796306014061, -0.07615648955106735, -0.019692298024892807, 0.009230334311723709, -0.024303287267684937, 0.022317495197057724, -0.01791239343583584, -0.166049525141716, 0.07448063790798187, -0.08264139294624329, 0.10739314556121826, 0.02096664533019066, -0.013569721020758152, -0.029745297506451607, 0.1476493924856186, -0.09873992949724197, -0.07932742685079575, 0.06899549067020416, -0.04696693271398544, 0.016178715974092484, -0.01142702903598547, -0.050053540617227554, 0.018854230642318726, -0.028981909155845642, -0.06913894414901733, -0.07440310716629028, -0.09930108487606049, 0.04307365417480469, -0.08461645245552063, -0.051056522876024246, 0.10762131214141846, 0.020709145814180374, -0.04422497749328613, -0.01214546523988247, -0.1278066486120224, 0.03402769938111305, 0.030657777562737465, 0.15061615407466888, -0.06729826331138611, -0.059687137603759766, -0.017392581328749657, 0.13856087625026703, -0.04061438515782356, -0.00620382372289896, -0.0947987362742424, -0.012570970691740513, 0.17616191506385803, 0.07976127415895462, 0.04894382506608963, -0.018007123842835426, 0.037964679300785065, 0.049889955669641495, -0.05427396297454834, -0.01977488212287426, -0.029874181374907494, -0.13401439785957336, 0.04838745668530464, 0.1401606798171997, -0.09897200018167496, 0.04574625939130783, -0.16030819714069366, 0.030548300594091415, 0.019324535503983498, -0.017300622537732124, -0.034617770463228226, 0.014186273328959942, 0.0008947686292231083, -0.004672572948038578, -0.051483120769262314, 0.1228240355849266, -0.0506686195731163, -0.021724989637732506, -0.10997825115919113, 0.04717635735869408, 0.05006147921085358, 0.09930858016014099, -0.07091411203145981, -0.0984974056482315, 0.015266478061676025, -0.11939449608325958, -0.12812946736812592, 0.0777917206287384, 0.05198545753955841, 0.08210770040750504, 0.032032936811447144, 0.06649505347013474, 0.10915936529636383, -0.13756313920021057, -0.04694909229874611, -0.128617063164711, -0.16389717161655426, 0.09098630398511887, 0.03728471323847771, -0.07387875765562057, -0.05995091795921326, -0.01989486627280712, 0.002769306767731905, 0.21883508563041687, 0.11310775578022003, -0.041573941707611084, 0.0061333682388067245, 0.07203278690576553, 0.12475842237472534, 0.1583476960659027, 0.002214655512943864, 0.08244206756353378, 0.10146477818489075, 0.01840779557824135, 0.013144607655704021, 0.040844570845365524, 0.3167880177497864, 0.0036888807080686092, 0.1345803588628769, -0.0306259635835886, -0.113215871155262, -0.09830162674188614, -0.03887374699115753, 0.05299921706318855, 0.002694128081202507, 0.08399160206317902, 0.03890671953558922, 0.1581781506538391, 0.1461598128080368, 0.07995294779539108, 0.0003878655261360109, -0.037215426564216614, -0.053966570645570755, -0.06518447399139404, 0.13191230595111847, -0.06439723819494247, 0.11348292976617813, -0.056775789707899094, -0.2312983125448227, 0.01792462356388569, 0.0015316363424062729, -0.08961576223373413, 0.02023899555206299, 0.02075290121138096, -0.016837486997246742, -0.04416491836309433, 0.044938649982213974, 0.06784945726394653], is_train=False, author_id=5036)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd2ccfa4-5034-494a-813c-9d342597dfe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[author_id: int, features: vector, is_train: boolean]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.select(\"author_id\", array_to_vector(\"features\").alias(\"features\"), \"is_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdd5c488-772c-4209-a0d7-d9e7ed28d53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=[-0.033117614686489105, 0.12483888119459152, -0.1549590528011322, -0.05444326251745224, 0.10045762360095978, -0.05532223358750343, -0.0026100422255694866, -0.08408316224813461, -0.03065658174455166, 2.3531155586242676, -0.11757563799619675, -0.0012547832448035479, 0.06489349901676178, -0.07668668776750565, -0.14405636489391327, -0.07120014727115631, -0.08332885056734085, 0.932112455368042, -0.16846469044685364, -0.04060450568795204, 0.02029799297451973, -0.07106799632310867, -0.06717848777770996, -0.00455648684874177, 0.0029725641943514347, 0.025969045236706734, -0.07220955193042755, -0.05050615593791008, 0.03428267315030098, -0.07148827612400055, -0.05324846878647804, 0.1629950851202011, -0.0616370253264904, 0.06018863990902901, 0.0775580033659935, -0.0882159098982811, -0.03288496285676956, 0.0039817257784307, -0.07003581523895264, -0.09210877865552902, -0.009599561803042889, 0.11958678811788559, -0.012092802673578262, -0.0970168188214302, 0.08391684293746948, 0.0025610795710235834, -0.10697278380393982, -0.040820859372615814, 0.01754629984498024, 0.029467983171343803, -0.0639696791768074, 0.06902561336755753, -0.05311295762658119, 0.02016288973391056, 0.09377744048833847, 0.010480932891368866, -0.02275271899998188, -0.06056026369333267, -0.02128669247031212, -0.07074809819459915, -0.0009982542833313346, -0.02995940111577511, -0.06633947789669037, 0.12387998402118683, 0.033253200352191925, -0.04056509584188461, -0.03861774131655693, 0.04701641947031021, 0.06704041361808777, 0.0616486556828022, 0.05022525042295456, 0.04858491197228432, 0.1713162511587143, -0.050370484590530396, 0.07761601358652115, -0.011932207271456718, 0.07519057393074036, -0.09055464714765549, -0.04938611015677452, 0.16826772689819336, -0.024284392595291138, 0.048620857298374176, -0.17441757023334503, -0.06427251547574997, 0.044218290597200394, -0.18639038503170013, -0.029675224795937538, -0.1767309159040451, 0.16986137628555298, 0.013417968526482582, -0.1244347020983696, -0.003843878861516714, -0.023192226886749268, 0.040279973298311234, 0.09668155759572983, 0.016692442819476128, 0.0022713958751410246, -0.05988452583551407, 0.0040757497772574425, -0.05388602614402771, 0.0011548990150913596, 0.009127420373260975, -0.05451923608779907, -0.03307902067899704, 0.08624482154846191, -0.9571686387062073, 0.051595140248537064, 0.028557587414979935, -0.013276370242238045, -0.017843084409832954, 0.026077475398778915, -0.09712652862071991, 0.0889841839671135, -0.07354483753442764, 0.057219453155994415, -0.01622706465423107, 0.0036540806759148836, 0.0437002032995224, -0.04523693770170212, 0.019135726615786552, 0.0511358268558979, -0.09104470908641815, -0.012911994010210037, -0.0001246633764822036, 0.04236485809087753, 0.040779419243335724, -0.04486502334475517, -0.15099719166755676, 0.008578073233366013, -0.012241754680871964, -0.002931973896920681, -0.00864738505333662, -0.10255102068185806, 0.01331371907144785, 0.09630066156387329, 0.03406396135687828, 0.017383268103003502, -0.008950348012149334, 0.013127757236361504, -0.03879281133413315, -1.3073159456253052, 0.06838927417993546, 0.10614411532878876, 0.017500076442956924, 0.057572297751903534, -0.09308645874261856, -0.019148530438542366, 0.004914383869618177, 0.03349785506725311, -0.08638906478881836, -0.029016027227044106, -0.017808305099606514, 0.07886834442615509, -0.0027399067766964436, -0.058389812707901, -0.008912735618650913, -0.10227398574352264, -0.048012685030698776, -0.05972796306014061, -0.07615648955106735, -0.019692298024892807, 0.009230334311723709, -0.024303287267684937, 0.022317495197057724, -0.01791239343583584, -0.166049525141716, 0.07448063790798187, -0.08264139294624329, 0.10739314556121826, 0.02096664533019066, -0.013569721020758152, -0.029745297506451607, 0.1476493924856186, -0.09873992949724197, -0.07932742685079575, 0.06899549067020416, -0.04696693271398544, 0.016178715974092484, -0.01142702903598547, -0.050053540617227554, 0.018854230642318726, -0.028981909155845642, -0.06913894414901733, -0.07440310716629028, -0.09930108487606049, 0.04307365417480469, -0.08461645245552063, -0.051056522876024246, 0.10762131214141846, 0.020709145814180374, -0.04422497749328613, -0.01214546523988247, -0.1278066486120224, 0.03402769938111305, 0.030657777562737465, 0.15061615407466888, -0.06729826331138611, -0.059687137603759766, -0.017392581328749657, 0.13856087625026703, -0.04061438515782356, -0.00620382372289896, -0.0947987362742424, -0.012570970691740513, 0.17616191506385803, 0.07976127415895462, 0.04894382506608963, -0.018007123842835426, 0.037964679300785065, 0.049889955669641495, -0.05427396297454834, -0.01977488212287426, -0.029874181374907494, -0.13401439785957336, 0.04838745668530464, 0.1401606798171997, -0.09897200018167496, 0.04574625939130783, -0.16030819714069366, 0.030548300594091415, 0.019324535503983498, -0.017300622537732124, -0.034617770463228226, 0.014186273328959942, 0.0008947686292231083, -0.004672572948038578, -0.051483120769262314, 0.1228240355849266, -0.0506686195731163, -0.021724989637732506, -0.10997825115919113, 0.04717635735869408, 0.05006147921085358, 0.09930858016014099, -0.07091411203145981, -0.0984974056482315, 0.015266478061676025, -0.11939449608325958, -0.12812946736812592, 0.0777917206287384, 0.05198545753955841, 0.08210770040750504, 0.032032936811447144, 0.06649505347013474, 0.10915936529636383, -0.13756313920021057, -0.04694909229874611, -0.128617063164711, -0.16389717161655426, 0.09098630398511887, 0.03728471323847771, -0.07387875765562057, -0.05995091795921326, -0.01989486627280712, 0.002769306767731905, 0.21883508563041687, 0.11310775578022003, -0.041573941707611084, 0.0061333682388067245, 0.07203278690576553, 0.12475842237472534, 0.1583476960659027, 0.002214655512943864, 0.08244206756353378, 0.10146477818489075, 0.01840779557824135, 0.013144607655704021, 0.040844570845365524, 0.3167880177497864, 0.0036888807080686092, 0.1345803588628769, -0.0306259635835886, -0.113215871155262, -0.09830162674188614, -0.03887374699115753, 0.05299921706318855, 0.002694128081202507, 0.08399160206317902, 0.03890671953558922, 0.1581781506538391, 0.1461598128080368, 0.07995294779539108, 0.0003878655261360109, -0.037215426564216614, -0.053966570645570755, -0.06518447399139404, 0.13191230595111847, -0.06439723819494247, 0.11348292976617813, -0.056775789707899094, -0.2312983125448227, 0.01792462356388569, 0.0015316363424062729, -0.08961576223373413, 0.02023899555206299, 0.02075290121138096, -0.016837486997246742, -0.04416491836309433, 0.044938649982213974, 0.06784945726394653], is_train=False, author_id=5036)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c7a50b-824b-42eb-a758-d908935978f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/25 16:41:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/25 16:41:23 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"SparkTFIDF\") \\\n",
    "            .set('spark.local.dir', '/media/volume/team11data/tmp') \\\n",
    "            .set('spark.driver.memory', '50G') \\\n",
    "            .set('spark.driver.maxResultSize', '25G') \\\n",
    "            .set('spark.executor.memory', '10G')\n",
    "sc = SparkContext(conf = conf)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "spark = SparkSession(sc)\n",
    "# dataset = spark.read.parquet(\"data/primary_authors/dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81ed8916-4d2d-43a4-8271-36951c78baca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(book_id=19, text='the adventure of the cardboard box by sir arthur conan doyle in choosing a few typical cases which illustrate the remarkable mental qualities of my friend sherlock holmes i have endeavoured as far as possible to select those which presented the minimum of sensationalism while offering a fair field for his talents it is however unfortunately impossible entirely to separate the sensational from the criminal and a chronicler is left in the dilemma that he must either sacrifice details which are essential to his statement and so give a false impression of the problem or he must use matter which chance and not choice has provided him with with this short preface i shall turn to my notes of what proved to be a strange though a peculiarly terrible chain of events it was a blazing hot day in august baker street was like an oven and the glare of the sunlight upon the yellow brickwork of the house across the road was painful to the eye it was hard to believe that these were the same walls which loomed so gloomily through the fogs of winter our blinds were and holmes lay curled upon the sofa reading and a letter which he had received by the morning post for myself my term of service in india had trained me to stand heat better than cold and a thermometer at ninety was no hardship but the morning paper was uninteresting parliament had risen everybody was out of town and i yearned for the glades of the new forest or the shingle of southsea a depleted bank account had caused me to postpone my holiday and as to my companion neither the country nor the sea presented the slightest attraction to him he loved to lie in the very center of five millions of people with his filaments stretching out and running through them responsive to every little rumour or suspicion of unsolved crime appreciation of nature found no place among his many gifts and his only change was when he turned his mind from the of the town to track down his brother of the country finding that holmes was too absorbed for conversation i had tossed aside the barren paper and leaning back in my chair i fell into a brown study suddenly my companion voice broke in upon my thoughts you are right watson said he it does seem a most preposterous way of settling a dispute most preposterous i exclaimed and then suddenly realizing how he had echoed the inmost thought of my soul i sat up in my chair and stared at him in blank amazement what is this holmes i cried this is beyond anything which i could have imagined he laughed heartily at my perplexity you remember said he that some little time ago when i read you the passage in one of poe sketches in which a close reasoner follows the unspoken thoughts of his companion you were inclined to treat the matter', author_id=5036)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "585fc564-2fdd-4899-8afa-838d0a99949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a72d5b-c7a8-44f2-8daf-5ebbbe4da98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(book_id=0, text='illustration had she taken sides with either of them with a single movement the victory would have been decided in that favor the crystal stopper by maurice leblanc contents chapter i the arrests ii eight from nine leaves one iii the home life of alexis daubreco iv the chief of the enemies the vi the vii the profile of napoleon viii the tower ix in the dark xi the cross of lorraine xii the scaffold xiii the last battle illustrations had she taken sides with either of them with a single movement the victory would have been decided in that favor lupin took his servant by the shoulders and shook him said beaumont are you sure brought you the indomitable chief of our enemies have you a feeding bottle quiet be quiet she cried clutching him fiercely say lupin sprang to his feet he was prepared for every upshot except this we have to do is to stop the mischief and you understand the thing will be the sight which she beheld struck her with stupefaction daubrecq ran up to prasville out of breath and caught hold of him with his two enormous hands chapter i the arrests the two boats fastened to the little pier that jutted out from the garden lay rocking in its shadow here and there lighted windows showed through the thick mist on the margins of the lake the enghien casino opposite blazed with light though it was late in the season the end of september a few stars appeared through the clouds a light breeze ruffled the surface of the water arsÃ¨ne lupin left the where he was smoking a cigar and bending forward at the end of the pier he asked are you there a man rose from each of the boats and one of them answered ready i hear the car coming with gilbert and he crossed the garden walked round a house in process of construction the scaffolding of which loomed overhead and cautiously opened the door on the avenue de ceinture he was not mistaken a bright light flashed round the bend and a large open drew up whence sprang two men in with the collars turned up and caps it was gilbert and vaucheray gilbert a young fellow of twenty or with an attractive cast of features and a supple and sinewy frame vaucheray older shorter with grizzled hair and a pale sickly face asked lupin you see him the deputy governor said gilbert saw him take the tram for paris as we knew he we are free to act the villa is ours to do as we please the chauffeur had kept his seat lupin gave him his orders wait here it might attract attention be back at nine exactly in time to load the car unless the whole business falls should it fall through observed gilbert the motor drove away and lupin taking the road to the lake with his two companions replied because i prepare the', author_id=10294, is_train=False)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7cf5c7bb-5646-4598-a244-4344d123b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"data/primary_authors/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "04874df0-104c-49bb-9a75-57dde1e23fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "Doyle, Arthur Conan                  84\n",
       "Chesterton, G. K. (Gilbert Keith)    61\n",
       "Leblanc, Maurice                     20\n",
       "Christie, Agatha                     12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f687b51-be47-466d-afa2-f1c82ebf6e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3928,  0.9512,  0.8813,  0.0199],\n",
       "        [ 1.3431, -1.0503,  1.1941, -1.2154],\n",
       "        [-2.0464,  1.4371,  1.6788,  0.0622],\n",
       "        [-1.5129,  2.2014,  0.4617, -0.3892]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(4, 4)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb47a5d4-cd9d-4503-9dea-bd735287f695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 2, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(t, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3d978f2-e2f5-4b1e-8ee4-e609b21f5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([str(x % 8) for x in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcd77b3c-5a29-4be5-9472-0b4c08e3bb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4', '5', '6', '7'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc0ae468-249c-430b-a45a-65b537008e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/primary_authors/dataset.parquet\")\n",
    "df = book_train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ba28ffc-eb89-48a2-9241-4142c0324ff7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=SparkTFIDF, master=local[*]) created by __init__ at /tmp/ipykernel_150470/882900860.py:6 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tfidf, we \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/primary_authors/dataset.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprimary_authors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/volume/team11data/524Project-Group11/proj2/feature_engineering.py:389\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(data_path, config_name, data_dir, embeddings_index, label_col)\u001b[0m\n\u001b[1;32m    387\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# IF YOU DONT HAVE THE GLOVE EMBEDDINGS, WILL DOWNLOAD 2GB FILE.\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m embeddings_index \u001b[38;5;241m=\u001b[39m \u001b[43mfean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_glove_vecs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# vecs = fean.generate_glove_vecs_with_tfidf(embeddings_index)\u001b[39;00m\n\u001b[1;32m    391\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished getting word embeddings (took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/volume/team11data/524Project-Group11/proj2/feature_engineering.py:314\u001b[0m, in \u001b[0;36mFeatureAnalysis.generate_glove_vecs\u001b[0;34m(self, embeddings_index)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_parquet(out_file)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspark \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_spark()\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# WILL DOWNLOAD 2GB FILE\u001b[39;00m\n\u001b[1;32m    316\u001b[0m embed_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/volume/team11data/524Project-Group11/proj2/feature_engineering.py:219\u001b[0m, in \u001b[0;36mFeatureAnalysis.start_spark\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_spark\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconf \u001b[38;5;241m=\u001b[39m SparkConf()\u001b[38;5;241m.\u001b[39msetMaster(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal[*]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msetAppName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparkTFIDF\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspark.local.dir\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/media/volume/team11data/tmp\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspark.driver.memory\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m50G\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspark.driver.maxResultSize\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m25G\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspark.executor.memory\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10G\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msc\u001b[38;5;241m.\u001b[39msetLogLevel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# sc.setLogLevel(\"ERROR\")\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/context.py:201\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m     )\n\u001b[0;32m--> 201\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[1;32m    204\u001b[0m         master,\n\u001b[1;32m    205\u001b[0m         appName,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m         memory_profiler_cls,\n\u001b[1;32m    216\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/context.py:449\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    446\u001b[0m     callsite \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\u001b[38;5;241m.\u001b[39m_callsite\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;66;03m# Raise error if there is already a running Spark context\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    450\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot run multiple SparkContexts at once; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexisting SparkContext(app=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, master=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m created by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    454\u001b[0m             currentAppName,\n\u001b[1;32m    455\u001b[0m             currentMaster,\n\u001b[1;32m    456\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mfunction,\n\u001b[1;32m    457\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mfile,\n\u001b[1;32m    458\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mlinenum,\n\u001b[1;32m    459\u001b[0m         )\n\u001b[1;32m    460\u001b[0m     )\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;241m=\u001b[39m instance\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=SparkTFIDF, master=local[*]) created by __init__ at /tmp/ipykernel_150470/882900860.py:6 "
     ]
    }
   ],
   "source": [
    "tfidf, we = extract_features(\"data/primary_authors/dataset.parquet\", config_name=\"primary_authors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "12847a18-87eb-447a-b3d6-e6c18b9eac6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15208</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15209</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15210</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15211</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15212</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15213 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred label\n",
       "0         2     0\n",
       "1         2     0\n",
       "2         2     0\n",
       "3         2     0\n",
       "4         2     0\n",
       "...     ...   ...\n",
       "15208     2     3\n",
       "15209     2     3\n",
       "15210     2     3\n",
       "15211     2     3\n",
       "15212     2     3\n",
       "\n",
       "[15213 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl = pd.read_parquet(\"data/primary_authors/tfidf/svm_preds_and_labels.parquet\")\n",
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e275c9e1-f264-4205-a5b0-40463775fd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8103.,    0.,    0.,    0.],\n",
       "       [3966.,    0.,    0.,    0.],\n",
       "       [2382.,    0.,    0.,    0.],\n",
       "       [ 762.,    0.,    0.,    0.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.loadtxt(\"data/primary_authors/tfidf/gaussian/confusion_matrix.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9702d28-e25c-427c-ad3f-bdf72084cdc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b89e00e2-dd15-4662-9dad-5847cb5d01ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3258: 0, 3304: 1, 5036: 2, 10294: 3}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65b44812-0f09-4292-bc62-a6aa4642ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl['author_id'] = tbl.author_id.apply(lambda x: d[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db02eaf3-faf6-4841-b0b6-9679ec304aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0.0113648325, 0.009577184, 0.0042619244, 0.00...\n",
       "1        [0.013048511, 0.015733944, 0.0056825657, 0.006...\n",
       "2        [0.012627591, 0.011629437, 0.00331483, 0.00673...\n",
       "3        [0.010943913, 0.019154368, 0.007103207, 0.0077...\n",
       "4        [0.012206672, 0.017786197, 0.004735471, 0.0077...\n",
       "                               ...                        \n",
       "19004    [0.011785752, 0.0143657755, 0.00994449, 0.0067...\n",
       "19005    [0.011785752, 0.019154368, 0.00662966, 0.00399...\n",
       "19006    [0.010522993, 0.017102113, 0.008050301, 0.0037...\n",
       "19007    [0.01389035, 0.013681691, 0.0042619244, 0.0048...\n",
       "19008    [0.012206672, 0.011629437, 0.008050301, 0.0058...\n",
       "Name: features, Length: 19009, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1bc30dc8-69b7-4112-bf7b-0e1202e43307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "19004    3\n",
       "19005    3\n",
       "19006    3\n",
       "19007    3\n",
       "19008    3\n",
       "Name: author_id, Length: 19009, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl.author_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50fce393-80f8-436d-ab2d-59194584b8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0164, 0.0109, 0.0047,  ..., 0.0101, 0.0144, 0.0096],\n",
       "        [0.0126, 0.0123, 0.0066,  ..., 0.0128, 0.0123, 0.0070],\n",
       "        [0.0173, 0.0055, 0.0052,  ..., 0.0109, 0.0096, 0.0063],\n",
       "        ...,\n",
       "        [0.0072, 0.0130, 0.0085,  ..., 0.0116, 0.0089, 0.0085],\n",
       "        [0.0114, 0.0130, 0.0085,  ..., 0.0114, 0.0089, 0.0074],\n",
       "        [0.0168, 0.0116, 0.0066,  ..., 0.0118, 0.0103, 0.0077]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.array(tbl[tbl.is_train].features.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "78b5c725-3531-47d7-ab74-ea03cf143611",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame(tfidf['features'].apply(lambda a: a['values']).tolist())\n",
    "# t = pd.DataFrame(we['final_vector'].apply(lambda a: a['values']).tolist())\n",
    "t = t.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3512a4d2-3232-495d-96ad-459add09b67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009681</td>\n",
       "      <td>0.009577</td>\n",
       "      <td>0.010418</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.015628</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>0.013682</td>\n",
       "      <td>0.011839</td>\n",
       "      <td>0.006839</td>\n",
       "      <td>0.012207</td>\n",
       "      <td>0.009207</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>0.024310</td>\n",
       "      <td>0.006839</td>\n",
       "      <td>0.014731</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>0.006261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013469</td>\n",
       "      <td>0.010261</td>\n",
       "      <td>0.013733</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.013313</td>\n",
       "      <td>0.008997</td>\n",
       "      <td>0.018470</td>\n",
       "      <td>0.014206</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.010102</td>\n",
       "      <td>0.008471</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.004735</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>0.019680</td>\n",
       "      <td>0.009470</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.018470</td>\n",
       "      <td>0.007366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010102</td>\n",
       "      <td>0.019154</td>\n",
       "      <td>0.009944</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>0.008997</td>\n",
       "      <td>0.010261</td>\n",
       "      <td>0.012786</td>\n",
       "      <td>0.006839</td>\n",
       "      <td>0.005893</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>0.010733</td>\n",
       "      <td>0.004735</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.017364</td>\n",
       "      <td>0.006576</td>\n",
       "      <td>0.012626</td>\n",
       "      <td>0.015050</td>\n",
       "      <td>0.014364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014311</td>\n",
       "      <td>0.012314</td>\n",
       "      <td>0.008997</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.014470</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.021891</td>\n",
       "      <td>0.010892</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>0.009681</td>\n",
       "      <td>0.007734</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.010418</td>\n",
       "      <td>0.004051</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>0.012155</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.008838</td>\n",
       "      <td>0.015734</td>\n",
       "      <td>0.011049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009681</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>0.009944</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.016207</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>0.021207</td>\n",
       "      <td>0.012312</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.005893</td>\n",
       "      <td>0.010733</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.007893</td>\n",
       "      <td>0.015628</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.008838</td>\n",
       "      <td>0.019838</td>\n",
       "      <td>0.012154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19004</th>\n",
       "      <td>0.015574</td>\n",
       "      <td>0.017786</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>0.005473</td>\n",
       "      <td>0.009944</td>\n",
       "      <td>0.006576</td>\n",
       "      <td>0.007997</td>\n",
       "      <td>0.004051</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>0.021416</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>0.012314</td>\n",
       "      <td>0.011049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19005</th>\n",
       "      <td>0.013890</td>\n",
       "      <td>0.010261</td>\n",
       "      <td>0.006630</td>\n",
       "      <td>0.008838</td>\n",
       "      <td>0.020837</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>0.009577</td>\n",
       "      <td>0.013733</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.015995</td>\n",
       "      <td>0.005156</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.012102</td>\n",
       "      <td>0.023731</td>\n",
       "      <td>0.004998</td>\n",
       "      <td>0.009049</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>0.008839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19006</th>\n",
       "      <td>0.013890</td>\n",
       "      <td>0.015734</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.007997</td>\n",
       "      <td>0.013313</td>\n",
       "      <td>0.011839</td>\n",
       "      <td>0.011629</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>0.005893</td>\n",
       "      <td>0.009155</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.005156</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>0.026046</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.006261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19007</th>\n",
       "      <td>0.013469</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>0.019101</td>\n",
       "      <td>0.013733</td>\n",
       "      <td>0.013682</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.013049</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>0.005683</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>0.025468</td>\n",
       "      <td>0.006839</td>\n",
       "      <td>0.009470</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>0.006629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19008</th>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19009 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0      0.009681  0.009577  0.010418  0.005471  0.015628  0.011365  0.013682   \n",
       "1      0.013469  0.010261  0.013733  0.005471  0.013313  0.008997  0.018470   \n",
       "2      0.010102  0.019154  0.009944  0.007365  0.017943  0.008997  0.010261   \n",
       "3      0.014311  0.012314  0.008997  0.006313  0.014470  0.008524  0.021891   \n",
       "4      0.009681  0.014366  0.009944  0.008207  0.016207  0.007577  0.021207   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19004  0.015574  0.017786  0.011365  0.006734  0.017943  0.007577  0.005473   \n",
       "19005  0.013890  0.010261  0.006630  0.008838  0.020837  0.008050  0.009577   \n",
       "19006  0.013890  0.015734  0.006156  0.007997  0.013313  0.011839  0.011629   \n",
       "19007  0.013469  0.010945  0.004262  0.007786  0.019101  0.013733  0.013682   \n",
       "19008  0.000421  0.000684  0.000474  0.000842  0.001736  0.002052  0.000474   \n",
       "\n",
       "             7         8         9         10        11        12        13  \\\n",
       "0      0.011839  0.006839  0.012207  0.009207  0.008523  0.006156  0.002578   \n",
       "1      0.014206  0.009733  0.010102  0.008471  0.007576  0.004735  0.001473   \n",
       "2      0.012786  0.006839  0.005893  0.006629  0.010733  0.004735  0.004420   \n",
       "3      0.010892  0.008944  0.009681  0.007734  0.011364  0.010418  0.004051   \n",
       "4      0.012312  0.008418  0.009260  0.005893  0.010733  0.006156  0.001841   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19004  0.009944  0.006576  0.007997  0.004051  0.009786  0.007103  0.007366   \n",
       "19005  0.013733  0.008418  0.015995  0.005156  0.007576  0.008524  0.004420   \n",
       "19006  0.011365  0.008418  0.011786  0.005893  0.009155  0.006156  0.005156   \n",
       "19007  0.011365  0.009733  0.013049  0.006629  0.008523  0.005683  0.006629   \n",
       "19008  0.000789  0.000421  0.001105  0.000947  0.000474  0.000368  0.001736   \n",
       "\n",
       "             14        15        16        17        18        19  \n",
       "0      0.008419  0.024310  0.006839  0.014731  0.014366  0.006261  \n",
       "1      0.006314  0.019680  0.009470  0.010101  0.018470  0.007366  \n",
       "2      0.005262  0.017364  0.006576  0.012626  0.015050  0.014364  \n",
       "3      0.007366  0.012155  0.006313  0.008838  0.015734  0.011049  \n",
       "4      0.007893  0.015628  0.007102  0.008838  0.019838  0.012154  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "19004  0.006840  0.021416  0.007366  0.012205  0.012314  0.011049  \n",
       "19005  0.012102  0.023731  0.004998  0.009049  0.008209  0.008839  \n",
       "19006  0.011050  0.026046  0.007102  0.012205  0.002736  0.006261  \n",
       "19007  0.006840  0.025468  0.006839  0.009470  0.007525  0.006629  \n",
       "19008  0.000263  0.001052  0.001368  0.000737  0.000000  0.000000  \n",
       "\n",
       "[19009 rows x 20 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2a1aaf49-77a9-4bdc-9627-a79a2c388bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "635c8db4-a525-4328-9a69-a25b4220cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = t[~df.is_train]\n",
    "t_train = t[df.is_train]\n",
    "y_test = df.author_id[~df.is_train].cat.codes\n",
    "y_train = df.author_id[df.is_train].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0a52ef1-0668-46b0-a37f-1d7af93de54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 15:52:33.828412: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732290753.845830   32075 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732290753.852497   32075 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-22 15:52:33.877344: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Input\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2aff36d0-88cc-4c80-ac51-809fd550cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Torch(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM_Torch, self).__init__()\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=300, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, num_classes) #fully connected 1\n",
    "        # self.fc = nn.Linear(128, 1) #fully connected last layer\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=x.device)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=x.device)) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        tag_space = self.fc_1(output.view(len(x), -1))\n",
    "        scores = F.log_softmax(tag_space, dim=1)\n",
    "        return scores\n",
    "        \n",
    "        # hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        # out = self.relu(hn)\n",
    "        # out = self.fc_1(out) #first Dense\n",
    "        # # out = self.relu(out) #relu\n",
    "        # # out = self.fc(out) #Final Output\n",
    "        # return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "de77cdc9-baad-4b4e-b191-49014a1ec51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_tensor = torch.Tensor(t_train.to_numpy())\n",
    "y_tensor = torch.Tensor(y_train.to_numpy())\n",
    "t_final = torch.reshape(t_tensor, (t_tensor.shape[0],1,t_tensor.shape[1]))\n",
    "dataset = TensorDataset(t_final, y_tensor)\n",
    "\n",
    "t_test_tensor = torch.Tensor(t_test.to_numpy())\n",
    "y_test_tensor = torch.Tensor(y_test.to_numpy())\n",
    "t_test_final = torch.reshape(t_test_tensor, (t_test_tensor.shape[0],1,t_test_tensor.shape[1]))\n",
    "test_dataset = TensorDataset(t_test_final, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "45648453-a6c1-4d55-be2c-6268498737f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0118, 0.0130, 0.0114,  ..., 0.0097, 0.0150, 0.0088],\n",
       "        [0.0105, 0.0103, 0.0095,  ..., 0.0124, 0.0103, 0.0110],\n",
       "        [0.0143, 0.0082, 0.0114,  ..., 0.0105, 0.0144, 0.0129],\n",
       "        ...,\n",
       "        [0.0139, 0.0157, 0.0062,  ..., 0.0122, 0.0027, 0.0063],\n",
       "        [0.0135, 0.0109, 0.0043,  ..., 0.0095, 0.0075, 0.0066],\n",
       "        [0.0004, 0.0007, 0.0005,  ..., 0.0007,    nan,    nan]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b69764f-50cd-4a69-a4c4-b85a23ffb135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = LSTM_Torch(4, t_tensor.shape[0], 2, 1, 4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "for i in range(0, 10):\n",
    "    print(i)\n",
    "    for data, labels in DataLoader(dataset, batch_size=16):\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for data, labels in DataLoader(test_dataset, batch_size=16):\n",
    "        data = data\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "\n",
    "        preds = model(data)\n",
    "        test_preds = torch.argmax(preds, axis=1)\n",
    "        all_preds.extend(test_preds.numpy())\n",
    "        all_labels.extend(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f93679cb-5dc2-4dda-ba41-32937b8d4c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3802, 300])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_tensor.shape("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8850a49d-ccc4-4dba-bd0d-0cd075ff1d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " ...]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7492844c-bf6f-4fb7-a05e-61ab1f1486a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.02870673,  0.09970236, -0.15648854, ...,  0.02137689,\n",
       "          0.04841836,  0.07517256]],\n",
       "\n",
       "       [[ 0.02870673,  0.09970236, -0.15648854, ...,  0.02137689,\n",
       "          0.04841836,  0.07517256]],\n",
       "\n",
       "       [[ 0.02870673,  0.09970236, -0.15648854, ...,  0.02137689,\n",
       "          0.04841836,  0.07517256]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.03368383,  0.08731421, -0.13608781, ...,  0.03363849,\n",
       "          0.02873958,  0.04364791]],\n",
       "\n",
       "       [[ 0.03368383,  0.08731421, -0.13608781, ...,  0.03363849,\n",
       "          0.02873958,  0.04364791]],\n",
       "\n",
       "       [[ 0.03368383,  0.08731421, -0.13608781, ...,  0.03363849,\n",
       "          0.02873958,  0.04364791]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array(t[df.is_train])\n",
    "arr.reshape((arr.shape[0],1,arr.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86fc8215-bf08-462e-b6cf-18ebb3e5708e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "19004    3\n",
       "19005    3\n",
       "19006    3\n",
       "19007    3\n",
       "19008    3\n",
       "Length: 19009, dtype: int8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author_id'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d943b00-9324-4c52-9d15-c48686ddc4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19009, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6152167c-220a-4a03-8d77-3867dceecdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_parquet(\"data/primary_authors/document_embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e0f17f4-a5d8-466a-81aa-f2a22beacf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19009, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22d6500e-4d08-42f1-8edf-56a08ba94581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/volume/team11data/524Project-Group11/proj2/dataset_handling.py:67: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  count_df = df.groupby(['author_id', 'book_id']).count().reset_index()\n",
      "/media/volume/team11data/524Project-Group11/proj2/dataset_handling.py:65: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  sub_df = pd.concat([sub_df, book_row])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         True\n",
       "1         True\n",
       "2         True\n",
       "3         True\n",
       "4         True\n",
       "         ...  \n",
       "19004    False\n",
       "19005    False\n",
       "19006    False\n",
       "19007    False\n",
       "19008    False\n",
       "Name: is_train, Length: 19009, dtype: bool"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = book_train_test_split(df)['is_train']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f995360-f142-40fb-bc3c-5329f7aefd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = pd.read_parquet(\"data/primary_authors/dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "58fa047e-596b-47cf-8738-f0d2a151f918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>illustration had she taken sides with either o...</td>\n",
       "      <td>10294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>plan and when i do a thing myself i am only go...</td>\n",
       "      <td>10294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>avenue de ceinture and lupin and his two compa...</td>\n",
       "      <td>10294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>of it but what there is is pucka nothing the m...</td>\n",
       "      <td>10294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>to the house urged by a feeling of anxiety whi...</td>\n",
       "      <td>10294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19004</th>\n",
       "      <td>83</td>\n",
       "      <td>the last named to take over his flat the lette...</td>\n",
       "      <td>5036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19005</th>\n",
       "      <td>83</td>\n",
       "      <td>explained that he adopted the title of dentist...</td>\n",
       "      <td>5036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19006</th>\n",
       "      <td>83</td>\n",
       "      <td>sentenced to seven penal servitude on the evid...</td>\n",
       "      <td>5036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19007</th>\n",
       "      <td>83</td>\n",
       "      <td>own behalf he was advised by his counsel not t...</td>\n",
       "      <td>5036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19008</th>\n",
       "      <td>83</td>\n",
       "      <td>nine hundred and nine notes obvious typographi...</td>\n",
       "      <td>5036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19009 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       book_id                                               text author_id\n",
       "0            0  illustration had she taken sides with either o...     10294\n",
       "1            0  plan and when i do a thing myself i am only go...     10294\n",
       "2            0  avenue de ceinture and lupin and his two compa...     10294\n",
       "3            0  of it but what there is is pucka nothing the m...     10294\n",
       "4            0  to the house urged by a feeling of anxiety whi...     10294\n",
       "...        ...                                                ...       ...\n",
       "19004       83  the last named to take over his flat the lette...      5036\n",
       "19005       83  explained that he adopted the title of dentist...      5036\n",
       "19006       83  sentenced to seven penal servitude on the evid...      5036\n",
       "19007       83  own behalf he was advised by his counsel not t...      5036\n",
       "19008       83  nine hundred and nine notes obvious typographi...      5036\n",
       "\n",
       "[19009 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4459cdbf-37de-43f1-9d18-30750c35ff40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0]],\n",
       "\n",
       "       [[ 1,  1,  1]],\n",
       "\n",
       "       [[ 2,  2,  2]],\n",
       "\n",
       "       [[ 3,  3,  3]],\n",
       "\n",
       "       [[ 4,  4,  4]],\n",
       "\n",
       "       [[ 5,  5,  5]],\n",
       "\n",
       "       [[ 6,  6,  6]],\n",
       "\n",
       "       [[ 7,  7,  7]],\n",
       "\n",
       "       [[ 8,  8,  8]],\n",
       "\n",
       "       [[ 9,  9,  9]],\n",
       "\n",
       "       [[10, 10, 10]],\n",
       "\n",
       "       [[11, 11, 11]],\n",
       "\n",
       "       [[12, 12, 12]],\n",
       "\n",
       "       [[13, 13, 13]],\n",
       "\n",
       "       [[14, 14, 14]],\n",
       "\n",
       "       [[15, 15, 15]],\n",
       "\n",
       "       [[16, 16, 16]],\n",
       "\n",
       "       [[17, 17, 17]],\n",
       "\n",
       "       [[18, 18, 18]],\n",
       "\n",
       "       [[19, 19, 19]],\n",
       "\n",
       "       [[20, 20, 20]],\n",
       "\n",
       "       [[21, 21, 21]],\n",
       "\n",
       "       [[22, 22, 22]],\n",
       "\n",
       "       [[23, 23, 23]],\n",
       "\n",
       "       [[24, 24, 24]],\n",
       "\n",
       "       [[25, 25, 25]],\n",
       "\n",
       "       [[26, 26, 26]],\n",
       "\n",
       "       [[27, 27, 27]],\n",
       "\n",
       "       [[28, 28, 28]],\n",
       "\n",
       "       [[29, 29, 29]],\n",
       "\n",
       "       [[30, 30, 30]],\n",
       "\n",
       "       [[31, 31, 31]],\n",
       "\n",
       "       [[32, 32, 32]],\n",
       "\n",
       "       [[33, 33, 33]],\n",
       "\n",
       "       [[34, 34, 34]],\n",
       "\n",
       "       [[35, 35, 35]],\n",
       "\n",
       "       [[36, 36, 36]],\n",
       "\n",
       "       [[37, 37, 37]],\n",
       "\n",
       "       [[38, 38, 38]],\n",
       "\n",
       "       [[39, 39, 39]],\n",
       "\n",
       "       [[40, 40, 40]],\n",
       "\n",
       "       [[41, 41, 41]],\n",
       "\n",
       "       [[42, 42, 42]],\n",
       "\n",
       "       [[43, 43, 43]],\n",
       "\n",
       "       [[44, 44, 44]],\n",
       "\n",
       "       [[45, 45, 45]],\n",
       "\n",
       "       [[46, 46, 46]],\n",
       "\n",
       "       [[47, 47, 47]],\n",
       "\n",
       "       [[48, 48, 48]],\n",
       "\n",
       "       [[49, 49, 49]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = np.array([[x, x, x] for x in range(50)])\n",
    "ls.reshape((ls.shape[0], 1, ls.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81086164-24f2-480e-af7e-1149da0217a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71651a4b-506c-46c3-a712-7fb08ca15bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>final_vector</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>10294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>10294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>10294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>10294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>10294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18499</th>\n",
       "      <td>0</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>5036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18500</th>\n",
       "      <td>33</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>5036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18501</th>\n",
       "      <td>47</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>5036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18502</th>\n",
       "      <td>79</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>5036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18503</th>\n",
       "      <td>25</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>5036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3790 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       book_id                                       final_vector author_id\n",
       "0            5  {'type': 1, 'size': None, 'indices': None, 'va...     10294\n",
       "1            0  {'type': 1, 'size': None, 'indices': None, 'va...     10294\n",
       "2            6  {'type': 1, 'size': None, 'indices': None, 'va...     10294\n",
       "3           16  {'type': 1, 'size': None, 'indices': None, 'va...     10294\n",
       "4            8  {'type': 1, 'size': None, 'indices': None, 'va...     10294\n",
       "...        ...                                                ...       ...\n",
       "18499        0  {'type': 1, 'size': None, 'indices': None, 'va...      5036\n",
       "18500       33  {'type': 1, 'size': None, 'indices': None, 'va...      5036\n",
       "18501       47  {'type': 1, 'size': None, 'indices': None, 'va...      5036\n",
       "18502       79  {'type': 1, 'size': None, 'indices': None, 'va...      5036\n",
       "18503       25  {'type': 1, 'size': None, 'indices': None, 'va...      5036\n",
       "\n",
       "[3790 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl2[df2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
